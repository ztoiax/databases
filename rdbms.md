
<!-- vim-markdown-toc GFM -->

* [RDBMS (关系性数据库)](#rdbms-关系性数据库)
    * [基本理论](#基本理论)
    * [范式](#范式)
    * [分库分表](#分库分表)
        * [何时分库分表？](#何时分库分表)
        * [如何选择分表键](#如何选择分表键)
        * [分表划分策略如何选择](#分表划分策略如何选择)
        * [常见问题](#常见问题)
            * [分库后，事务问题](#分库后事务问题)
            * [跨节点Join关联问题](#跨节点join关联问题)
            * [order by,group by等聚合函数问题](#order-bygroup-by等聚合函数问题)
            * [分库分表后，分页问题](#分库分表后分页问题)
            * [分表后，ID怎么保证唯一性的呢？](#分表后id怎么保证唯一性的呢)
    * [index(索引)](#index索引)
        * [B+树(平衡树)](#b树平衡树)
        * [hash散列函数](#hash散列函数)
        * [顺序索引与散列索引对比](#顺序索引与散列索引对比)
        * [lsm(Log Structured Merge)](#lsmlog-structured-merge)
            * [阶梯式合并索引(Stepped Merge Index)](#阶梯式合并索引stepped-merge-index)
        * [b树对比lsm树](#b树对比lsm树)
        * [Buffer Tree](#buffer-tree)
        * [位图索引](#位图索引)
    * [TRANSACTION (事务)](#transaction-事务)
            * [并发控制(隔离性等级的实现)](#并发控制隔离性等级的实现)
                * [隔离性等级](#隔离性等级)
                * [mvcc](#mvcc)
                * [锁](#锁)
                    * [严格两阶段封锁协议(strict two-pyhase locking protocol):](#严格两阶段封锁协议strict-two-pyhase-locking-protocol)
                    * [图的协议](#图的协议)
                    * [多粒度机制(granularity)](#多粒度机制granularity)
                * [时间戳排序协议(timestamp-orderind protocol)](#时间戳排序协议timestamp-orderind-protocol)
                * [有效性检测协议(validation protocol)](#有效性检测协议validation-protocol)
                * [多版本时间戳排序协议(multivesion timestamp-ordering scheme)](#多版本时间戳排序协议multivesion-timestamp-ordering-scheme)
                * [多版本两阶段封锁协议(multivesion two-phase locking protocol)](#多版本两阶段封锁协议multivesion-two-phase-locking-protocol)
                * [快照隔离(Snapshot Isolation)](#快照隔离snapshot-isolation)
                * [谓词读(幻读 phantom)](#谓词读幻读-phantom)
                * [索引并发](#索引并发)
    * [日志(恢复系统)](#日志恢复系统)
        * [逻辑日志](#逻辑日志)
        * [ARIES: 目前最新的恢复技术](#aries-目前最新的恢复技术)
    * [JOIN(关联查询): 改变表关系](#join关联查询-改变表关系)
        * [基本概念](#基本概念)
        * [join的实现](#join的实现)
            * [SNLJ(简单嵌套循环):](#snlj简单嵌套循环)
            * [代价分析](#代价分析)
            * [block nested-loop(块嵌套循环):](#block-nested-loop块嵌套循环)
            * [代价分析](#代价分析-1)
            * [INLJ(索引嵌套循环):](#inlj索引嵌套循环)
            * [代价分析](#代价分析-2)
            * [merge join(归并连接)](#merge-join归并连接)
            * [代价分析](#代价分析-3)
            * [hash join(散列连接)](#hash-join散列连接)
    * [HTAP(Hybrid transaction/analytical processing) 混合事务 / 分析处理](#htaphybrid-transactionanalytical-processing-混合事务--分析处理)
        * [列存储](#列存储)
    * [第三方工具](#第三方工具)

<!-- vim-markdown-toc -->

# RDBMS (关系性数据库)

## 基本理论

- 结构化存储(structured storage systems): 强调`Consistency`(一致性)

  - SQL语句并不区分大小写

  - 关系模型在逻辑层和视图层描述数据,不必关注数据存储的底层细节

    - 元组指 行

    - 属性指 列

    - 关系指 表

      - 关系是元组(行)的集合,但和元组的排列顺序没关

    - 关系模式:由属性(列)组成,数据库的逻辑设计

    - 关系实例:数据库的数据值

      - 关系模式不会发生变化,而关系实例会随时间变化
- 查询

  - 过程化语言

    - 以计算为操作的结果

    - 从单个关系中(id),选出满足一定条件的特殊元组(> 10)

      ```sql
      select * from cnarea_2019
      where id > 100
      ```

    - 从单个关系中,选出特定的属性(id)

      ```sql
      select id from cnarea_2019
      ```

    - 两种计算:id > 100,选出 id,name 属性

      ```sql
      select id,name from cnarea_2019
      where id > 100
      ```

    - 连接合并多个关系的元组

  - 非过程化语言

## 范式

- 完全范式化和完全反范式化在实际应用中很少用到, 实际上两者经常混用

- 范式化:

    - 优点:很少甚至没有重复数据

    - 缺点:表之间连接的代价

    - 假设有两张表:

        - 用户表, 用户发送信息的表.只有付费用户可以查询最近的10条信息

        - 则需要连接两张表, 查询用户表有哪些付费用户, 再查询用户发送信息

        - 如果付费的用户很少, 查询的效率会很低

        - 如果采用反范式化, 只有一张表, 建立索引后查询会非常高效

- 反范式化:

    - 优点:数据都在一张表, 没有连接

    - 缺点:重复数据

    - 缓存表:

        - 通过触发器更新缓存值

        - 有时需要定期重建表, 以此减少碎片

        - 由于MyISAM存储引擎有索引压缩的功能: 因此缓存表可以使用MyISAM, 从而减少磁盘空间

        - 假设需要过去24小时的数据, 可以每小时建一张缓存表

    - 物化视图:

        - mysql原生不支持物化视图, 可以使用[Flexviews第三方工具](https://github.com/greenlion/swanhart-tools)

        - 不需要查询原始数据, 因此比缓存表效率更高

## 分库分表

- [小林coding：分库分表 15 连问，你抗的住吗？](https://mp.weixin.qq.com/s/jPH679biI3CLXHTZr4q3xA)

- [腾讯技术工程：一文读懂数据库优化之分库分表](https://cloud.tencent.com/developer/article/2197011)

- 为什么分库分表？

    - 性能角度：CPU、内存、磁盘、IO 瓶颈
    - 可用性角度：如果是单库，数据库宕机会导致 100%服务不可用，N 库则可以将影响面降低 N 倍。

    ![image](./Pictures/rdbms/分库分表.avif)

- 分库分表中间件

    ![image](./Pictures/rdbms/分库分表中间件.avif)

- 分库：缓解单服务器的压力（CPU、内存、磁盘、IO）

    - 水平分库

        - 将表的**数据**拆分成不同库, 没有交集

        - 每个库的结构都一样; 数据不一样

        ![image](./Pictures/mysql/transverse_database.avif)

    - 垂直分库

        - 将表的**列字段**拆分成不同库, 没有交集

        - 每个库的结构都不一样; 数据也不一样

        ![image](./Pictures/mysql/vertical_database.avif)

- 分表：降低锁粒度以及索引树，提升数据查询效率。

    - 水平分表

        - 将表的**数据**拆分成不同表, 没有交集

        - 每个表的结构都一样; 数据不一样

        ![image](./Pictures/mysql/transverse_table.avif)

        - 首先根据业务场景来决定使用什么字段作为分表字段(sharding_key)，比如我们现在日订单1000万，我们大部分的场景来源于C端，我们可以用user_id作为sharding_key，数据查询支持到最近3个月的订单，超过3个月的做归档处理，那么3个月的数据量就是9亿，可以分1024张表，那么每张表的数据大概就在100万左右。

            - 比如用户id为100，那我们都经过hash(100)，然后对1024取模，就可以落到对应的表上了。


    - 垂直分表

        - 将表的**列字段**拆分成不同表, 有交集:每个表至少有一列交集(一般是主键)

        - 每个表的结构都不一样; 数据也不一样

        ![image](./Pictures/mysql/vertical_table.avif)

- 磁盘读 IO 瓶颈: 热点数据太多,数据库缓存放不下,每次查询时会产生大量的 IO,降低查询速度

    - 分库和垂直分表

- 网络 IO 瓶颈:请求的数据太多,网络带宽不够
    - 分库

- CPU 瓶颈第一种: SQL 中包含 join,group by,order by,非索引字段条件查询等

    - SQL 优化,建立合适的索引,在业务 Service 层进行业务计算

- CPU 瓶颈第二种: 单表数据量太大,查询时扫描的行太多

    - 水平分表

### 何时分库分表？

- 阿里巴巴的《Java开发手册》提出：单表行数超过500万行或者单表容量超过2GB，才推荐进行分库分表。

    - 是不是等到数据量到达五百万，才开始分库分表呢？不是这样的，我们应该提前规划分库分表，如果估算3年后，你的表都不会到达这个五百万，则不需要分库分表。

    - MySQL服务器如果配置更好，是不是可以超过这个500万这个量级，才考虑分库分表？虽然配置更好，可能数据量大之后，性能还是不错，但是如果持续发展的话，还是要考虑分库分表

- 疑问？MySQL 单表不要超过 2000 万行基本上是一个行业共识，只有当单表行数超过 500 万行或者单表容量超过 2GB，我们一般才推荐进行分库分表。

    - innodb存储引擎b+树估算

        - 假设：
            - 非叶子节点内指向其他数据页的指针数量为 X（即非叶子节点的最大子节点数为 X）
            - 每个叶子节点可以存储的行记录数为 Y
            - B+树的高度为 N（即  B+树的层数）

        - 公式：

            - 对于一个高度为 N 的 B+树，顶层（根节点）有一个非叶子节点，那么第二层就有X个节点，第三层就有 X 的2次方个节点，第四层就有 X 的三次方个节点，以此类推，第 N 层（即叶子节点所在的第 N 层）就有 X 的 N-1 次方个节点；
            - 在 B+ 树中，所有的记录都存储在叶子节点中，假设每个叶子节点都可以存储的行记录数为 Y；
            - 那么 B+ 树可以存储的数据总量为叶子节点总数乘以每个叶子节点存储的记录数
                - 即：M=（X 的 N-1 次方）乘以 Y；

        - 代入计算：

            - 一个数据页大小16K，扣除页号、前后指针、页目录，校验码等信息，实际可以存储数据的大约为15K，假设主键ID为bigint型，那么主键 ID 占用8个 byte，页号占用4个 byte，则 X=15*1024/(8 + 4) 等于1280；
            - 一个数据页实际可以存储数据的空间大小，大约为15K，假设一条行记录占用的空间大小为1K，那么一个数据页就可以存储15条行记录，即 Y=15；
            - 假设 B+树是两层的：则 N=2，即 M=1280的（2-1）次方 * 15 ≈ 2w ；
            - 假设 B+树是三层的：则 N=3，即 M=1280的2次方 * 15 ≈ 2.5 kw；
            - 假设 B+树是四层的：则 N=4，即 M=1280的3次方 * 15 ≈ 300亿

        - 综上所述，我们建议单表数据量大小在两千万。当然这个数据是根据每条行记录的大小为 1K 的时候估算而来的，而实际情况中可能并不是这个值，所以这个建议值两千万只是一个建议，而非一个标准。

- 什么类型业务表需要才分库分表？通用是一些流水表、用户表等才考虑分库分表，如果是一些配置类的表，则完全不用考虑，因为不太可能到达这个量级。

- 如果分库数量少，达不到分散存储和减轻DB性能压力的目的；如果分库的数量多，对于跨多个库的访问，应用程序需要访问多个库。

    - 一般是建议分4~10个库，我们公司的企业客户信息，就分了10个库。

### 如何选择分表键

- 分表键，即用来分库/分表的字段。如按用户ID分表、按时间分表、按地区分表，这些用户ID、时间、地区就是分表键。

    - 一般数据库表拆分的原则，需要先找到业务的主题。比如你的数据库表是一张企业客户信息表，就可以考虑用了客户号做为分表键。

- 非分表键如何查询

    - 分库分表后，有时候无法避免一些业务场景，需要通过非分表键来查询。

    - 假设一张用户表，根据userId做分表键，来分库分表。但是用户登录时，需要根据用户手机号来登陆。这时候，就需要通过手机号查询用户信息。而手机号是非分表键。

    - 非分表键查询，一般有这几种方案：

        - 遍历：最粗暴的方法，就是遍历所有的表，找出符合条件的手机号记录（不建议）
        - 将用户信息冗余同步到ES，同步发送到ES，然后通过ES来查询（推荐）
        - 其实还有基因法：比如非分表键可以解析出分表键出来，比如常见的，订单号生成时，可以包含客户号进去，通过订单号查询，就可以解析出客户号。但是这个场景除外，手机号似乎不适合冗余userId。

### 分表划分策略如何选择

- range范围：

    - 将表的主键order_id，按照从0~300万的划分为一个表，300万~600万划分到另外一个表。

        ![image](./Pictures/rdbms/分表策略-range.avif)

    - 按时间范围来划分，如不同年月的订单放到不同的表

    - 优点： range范围分表，有利于扩容。
    - 缺点：可能会有热点问题。因为订单id是一直在增大的，也就是说最近一段时间都是汇聚在一张表里面的。比如最近一个月的订单都在300万~600万之间，平时用户一般都查最近一个月的订单比较多，请求都打到order_1表啦。

    - 查询情况：
        - 基于属性的范围划分, 一般查询只需扫描单个磁盘
        - 适合范围查询, 单个属性值查询, 不适合整个关系查询

- hash：

    - 指定的路由key（一般是user_id、order_id、customer_no作为key）对分表总数进行取模，把数据分散到各个表中。

    - 比如原始订单表信息，我们把它分成4张分表：

        - id=1，对4取模，就会得到1，就把它放到t_order_1;
        - id=3，对4取模，就会得到3，就把它放到t_order_3;

        ![image](./Pictures/rdbms/分表策略-hash.avif)

    - 一般，我们会取哈希值，再做取余：

        ```sql
        Math.abs(orderId.hashCode()) % table_number
        ```

    - 优点：hash取模的方式，不会存在明显的热点问题。
    - 缺点：如果未来某个时候，表数据量又到瓶颈了，需要扩容，就比较麻烦。所以一般建议提前规划好，一次性分够。（可以考虑一致性哈希）

    - 查询情况：
        - 基于属性salary的划分时, 当执行 `salary = 10000 - 1000`查询语句时, 只需扫描保存这个属性值的单个磁盘

        - 适合单个属性值查询, 整个关系查询. 不适合范围查询

- 一致性Hash：

    - hash方式分表的问题：前期规划不好，需要扩容二次分表，表的数量需要增加，所以hash值需要重新计算，这时候需要迁移数据了。

        - 例子：开始分了10张表，之后业务扩展需要，增加到20张表。那问题就来了，之前根据orderId取模10后的数据分散在了各个表中，现在需要重新对所有数据重新取模20来分配数据

    - 一致性哈希：在移除或者添加一个服务器时，能够尽可能小地改变已存在的服务请求与处理请求服务器之间的映射关系。一致性哈希解决了简单哈希算法在分布式哈希表存在的动态伸缩等问题

        - RedisCluster 即是通过一致性 Hash 算法，使用 16384 个虚拟槽节点进行每个分片数据的管理。

- 如何避免热点问题数据倾斜（热点数据）

    - 最大数据偏斜率：（数据量最大样本 - 数据量最小样本）/ 数据量最小样本。一般来说，如果我们的最大数据偏斜率在 5%以内是可以接受的。

    - 问题：根据时间范围分片，某电商公司11月搞营销活动，那么大部分的数据都落在11月份的表里面了，其他分片表可能很少被查询，即数据倾斜了，有热点数据问题了。

    - 解决方法：range范围+hash取模

        - 在拆分库的时候，我们可以先用range范围方案，比如订单id在0~4000万的区间，划分为订单库1;id在4000万~8000万的数据，划分到订单库2,将来要扩容时，id在8000万~1.2亿的数据，划分到订单库3。然后订单库内，再用hash取模的策略，把不同订单划分到不同的表。

        ![image](./Pictures/rdbms/range范围+hash取模.avif)

    - 解决方法:虚拟结点(virtual node)

        - 创建实际结点几倍的虚拟结点,虚拟结点依次映射到实际结点

        - 随着关系的增长, 也会动态的创建新虚拟结点.并将数量更多虚拟结点移动到数量少的结点

        ![image](./Pictures/rdbms/virtual-node.avif)

### 常见问题

#### 分库后，事务问题

- 分库分表后，假设两个表在不同的数据库，那么本地事务已经无效啦，需要使用分布式事务了。

| 分布式事务   |
|--------------|
| 两阶段提交   |
| 三阶段提交   |
| TCC          |
| 本地消息表   |
| 最大努力通知 |
| saga         |

#### 跨节点Join关联问题

- 首先来自大厂 DBA 的建议是，线上服务尽可能不要有表的 join 操作，join 操作往往会给后续的分库分表操作带来各种问题，可能导致数据的死锁。可以采用多次查询业务层进行数据组装(需要考虑业务上多次查询的事务性的容忍度)

- 分库分表之后，两张表可能都不在同一个数据库中了，那么如何跨库join操作呢？

    - 1.字段冗余：把需要关联的字段放入主表中，避免关联操作
        - 例子：订单表保存了卖家ID（sellerId），你把卖家名字sellerName也保存到订单表，这就不用去关联卖家表了。这是一种空间换时间的思想。

    - 2.全局表：比如系统中所有模块都可能会依赖到的一些基础表（即全局表），在每个数据库中均保存一份。

    - 3.数据抽象同步：比如A库中的a表和B库中的b表有关联，可以定时将指定的表做同步，将数据汇合聚集，生成新的表。一般可以借助ETL工具。

    - 4.应用层代码组装：分开多次查询，调用不同模块服务，获取到数据后，代码层进行字段计算拼装。

####  order by,group by等聚合函数问题

- 方案一：赛道赛马机制，每次从 N 个库表中查询出 TOP N 数据，然后在业务层代码中进行聚合合并操作。

    ```sql
    假设： 以2库1表为例，每次分页查询N条数据。

    第一次查询：
    ① 每个表中分别查询出N条数据：
    SELECT * FROM db1_table1 where $col > 0 order by $col   LIMITT  0,N
    SELECT * FROM db2_table1 where $col > 0 order by $col   LIMITT  0,N
    ② 业务层代码对上述两者做归并排序，假设最终取db1数据K1条，取db2数据K2条，则K1+K2 = N
    此时的DB1 可以计算出OffSet为K1 ，DB2计算出Offset为K2
    将获取的N条数据以及相应的Offset  K1/K2返回给 端上。

    第二次查询：
    ① 端上将上一次查询对应的数据库的Offset  K1/K2 传到后端
    ② 后端根据Offset构造查询语句查询分别查询出N条语句
    SELECT * FROM db1_table1 where $col > 0 order by $col   LIMITT  $K1,N
    SELECT * FROM db2_table1 where $col > 0 order by $col   LIMITT  $K2,N
    ③ 再次使用归并排序，获取TOP N数据，将获取的N条数据以及相应的Offset  K1/K2返回给 端上。

    第三次查询:
    依次类推.......
    ```

- 方案二：可以将经常使用到 groupby,orderby 字段存储到一个单一库表(可以是 REDIS、ES、MYSQL)中，业务代码中先到单一表中根据查询条件查询出相应数据，然后根据查询到的主键 ID，到分库分表中查询详情进行返回。2 次查询操作难点会带来接口耗时的增加，以及极端情况下的数据不一致问题。

#### 分库分表后，分页问题

- 方案1（全局视野法）：在各个数据库节点查到对应结果后，在代码端汇聚再分页。这样优点是业务无损，精准返回所需数据；缺点则是会返回过多数据，增大网络传输

    - 例子：分库分表前，你是根据创建时间排序，然后获取第2页数据。如果你是分了两个库，那你就可以每个库都根据时间排序，然后都返回2页数据，然后把两个数据库查询回来的数据汇总，再根据创建时间进行内存排序，最后再取第2页的数据。

- 方案2（业务折衷法-禁止跳页查询）：这种方案需要业务妥协一下，只有上一页和下一页，不允许跳页查询了。

    - 这种方案，查询第一页时，是跟全局视野法一样的。但是下一页时，需要把当前最大的创建时间传过来，然后每个节点，都查询大于创建时间的一页数据，接着汇总，内存排序返回。

#### 分表后，ID怎么保证唯一性的呢？

- 因为主键默认都是自增的，那么分表之后的主键在不同表就肯定会有冲突了。有几个办法考虑：

    - 1.设定步长：比如1-1024张表我们分别设定1-1024的基础步长
        - 表1的ID范围是1-1024
        - 表2的ID范围是1025-2048
        - 表3的ID范围是2049-3072

    - 2.UUID/GUID：使用全局唯一标识符作为主键。

    - 3.分布式ID：自己实现一套分布式ID生成算法或者使用开源的如twitter的雪花算法

        - 一个Snowflake ID有64位。

        - 第1位：Java中long的最高位是符号位代表正负，正数是0，负数是1，一般生成ID都为正数，所以默认为0。
        - 接下来前41位是时间戳，表示了自选定的时期以来的毫秒数。
        - 接下来的10位代表计算机ID，防止冲突。
        - 其余12位代表每台机器上生成ID的序列号，这允许在同一毫秒内创建多个Snowflake ID。

        ![image](./Pictures/rdbms/snowflake-id.avif)

    - 4.分表后不使用主键作为查询依据：而是每张表单独新增一个字段作为唯一主键使用，比如订单表订单号是唯一的，不管最终落在哪张表都基于订单号作为查询依据，更新也一样。

## index(索引)

- 搜索码:查找记录的属性(列)或者属性集

- clustering index(聚簇索引或primary index主索引): 搜索码按指定顺序排序, 并且在同一结构下保存索引和数据行的物理位置

- no clustering index(非聚簇索引或secondary index二级索引): 搜索码**不**按顺序排序,叶结点保存的不是数据行的物理位置, 而是行指针, 因此需要2次查找:

    - 1.获取数据行在二级索引的行指针

    - 2.再从聚簇索引找数据行对应的物理位置

    - innodb使用主键值代替行指针:

        - 优点:移动行时无需更新这个指针

- 无论任何形式的索引, 面对插入和删除操作, 都需要更新

- dense index(稀疏索引): 按顺序存储部分搜索码, 因此**只有clustering index才能使用dense index**

   - 插入和删除

       - 如果是按顺序出现的第一个搜索码: 按顺序插入或删除

       - 否则: 不操作

    ![image](./Pictures/rdbms/dense_index.avif)
    ![image](./Pictures/rdbms/dense_index1.avif)

- sparse index(稠密索引): 每个搜索码都有一个索引项,每条索引项都是指针, 因此**no clustering index必须是sparse index**

    - 插入:

        - 如果没有搜索码: 找到合适的位置插入

        - 如果有相同的搜索码: 则在索引项增加指向该记录的指针

    - 删除:

        - 如果指向相同搜索码的第一条记录指针: 删除这条记录, 更新索引项指向下一条记录

    ![image](./Pictures/rdbms/sparse_index.avif)

- mulitilevel index (多级索引): 两极或以上的索引. 在很大的原始索引上构造一层dense index的外层索引

    - 10000个块的索引, 二分搜索需要14次(log2(b)), 平均每次10毫秒读取一块, 那么需要140毫秒

    - 利用多级索引: 10000个块需要10000个索引项, 也就是100个块, 大大减少磁盘IO

### B+树(平衡树)

- B树只允许搜索码出现一次

- B树有时不需要达到叶结点就能获取值

- B树的删除更加复杂, 有可能在非叶结点

- B+树胖和矮, 而二叉树高和瘦

    - 结点大小一般等同于磁盘块大小4KB

    - 假设搜索码=32B, n=100, 搜索码的值N = 100万, 一次查询只需要访问4个结点**(log[n/2] N)**

    - 平衡二叉树则是**(log2 N)**: 需要访问20个结点

- 叶结点:最多 `n-1` 个值, 最少 `(n-1)/2` 个值. 假设 n=4 叶结点最少包含2个, 最多3个值. 叶结点采用链表按顺序相连

- nonleaf node(非叶结点):最多 `n` 个指针, 最少 `n/2` 个指针. 形成对叶结点的多级稀疏索引, 不同于多索引顺序文件, 结点的指针数也叫**扇出**

- 插入和删除有可能会导致**分裂**, **合并**

    - 假设搜索码没有重复值, 最坏情况的删除复杂度是**log[n/2] N**

    - 随着树中不断的插入和删除, 会丧失IO的顺序性, 因此为了恢复顺序性需要重建索引

- 字符串索引的prefix compression(前缀压缩)技术: 非叶结点不需要存储完整的值, 只需存储前缀

    - 假设silberschatz的子树silas, silver. 只需存储前缀sil, 而不是存储silberschatz

- 对于不唯一搜索码, B+树会存储多次

### hash散列函数

> 理想的散列函数均匀的分布到所有的桶里, 使每个桶具有相同的记录

- 桶: 存储一条或多条记录, 桶大小一般等同于磁盘块

- 假设以工资为搜索码, 在1000-3000的记录的桶, 比 3000-6000的记录的桶多, 分布不均匀

- 桶溢出:

    - close addressing(闭地址): 假设3000-6000桶已经满了, 新插入的记录会添加到新桶里,以此类推. 3000-6000的桶与溢出桶使用链表连接在一起

    ![image](./Pictures/rdbms/bucket_overflows.avif)
    - open addressing(开地址): 假设3000-6000桶已经满了, 新插入的记录会添加到其它桶里. 删除操作很麻烦, 所以一般应用于只做查找, 插入的编译器符号表

- 动态散列: 通过桶的分裂, 合并适应数据库大小的变化. 性能不会随着数据库的增长而降低

- 维护一个中间层: 桶地址表

### 顺序索引与散列索引对比

- 此查询: 散列更优
```sql
SELECT A1, A2...An
FROM r
WHERE Ai = c
```

    - 顺序索引: 与关系r的Ai个数的对数成正比
    - 散列索引: 一个和数据库大小无关的常数

- 范围查询: 顺序更优
```sql
SELECT A1, A2...An
FROM r
WHERE Ai < c2 and Ai > c1
```

    - 顺序索引: 一旦找到c1就可以按顺序读取直到c2
    - 散列索引: 值是随机分布到不同的桶

### lsm(Log Structured Merge)

- lsm树

    ![image](./Pictures/rdbms/lsm.avif)

    - 先insert在内存中的L0树

    - L0树满了, 将L1树的记录与L0树合并, 再移动到L1树

        - Li -> Li+1以此类推

    - delete:标记删除的数据项, 返回时屏蔽标记的数据项, 合并时在删除数据项

    - 优点:

        - 顺序IO, 没有随机IO

        - 不修改已经存在的文件,因此不需要加锁

    - 缺点:

        - 查询可能会读取多个树

            - L0找不到就去L1找,以此类推

#### 阶梯式合并索引(Stepped Merge Index)

    ![image](./Pictures/rdbms/stepped-merge-index.avif)

    - 每层k个树

        - 一层中的k个树都满了, 就合并到下一层

    - 优点:

        - 减少写的开销

    - 缺点:

        - 查询需要读取更多的树

            - 优化:通过Bloom Filter(布隆过滤器), 快速判断数据是否在树里
    - update操作使用delete+insert

![image](./Pictures/rdbms/lsm.avif)

### b树对比lsm树

![image](./Pictures/rdbms/btree_vs_lsm.avif)

- 在不限制写入的情况下；
    - LSM 树的写入性能是 B 树的 1.5 ~ 2 倍；
    - LSM 树的读取性能是 B 树的 1/6 ~ 1/3；

- 在限制写入的情况下；
    - LSM 树的写入性能与 B 树的性能基本持平；
    - LSM 树的读取性能是 B 树的 1/4 ~ 1/2；
    - 每秒会写入 30,000 条数据，无论那种情况下 B 树的读取性能是远好于 LSM 树的。

- 对于大多数的 OLTP 系统来说，系统的查询会是写的很多倍

### Buffer Tree

![image](./Pictures/rdbms/buffer-tree.avif)

- 对B+树的优化

    - 为每个B+树结点, 都有buffer存储inserts

    - buffer满了, 就移动到低结点

### 位图索引

- 多码索引

- 位图索引很小, 大概是整个关系的1%

- 位图索引删除记录的代价很大, 一般在末尾添加新的记录

    - existence bitmap(存在位图): 通过位图中的1位, 当值为0时表示不存在

- 此查询: 计算A2, A1两个位图的交(与门), 如果有多条记录满足此条件, 则需要扫描整个关系
```sql
SELECT A1, A2...An
FROM r
WHERE A2 = c2 and A1 = c1
```

![image](./Pictures/rdbms/bigmap.avif)

## TRANSACTION (事务)

- 系统中可能会面临下面的问题：

    - 程序依托的操作系统层，硬件层可能随时都会发生故障（包括一个操作执行到一半时）。
    - 应用程序可能会随时发生故障（包括操作执行到一半时）。
    - 网络中断可能随时会发生，它会切断客户端与服务端的链接或数据库之间的链接。
    - 多个客户端可能会同时访问服务端，并且更新统一批数据，导致数据互相覆盖（临界区）。
    - 客户端可能会读到过期的数据，因为上面说的，可能操作执行一半应用程序就挂了。

- ACID

    - Atomic(原子性):原子表示的是不可分割。因此事务是不可分割的最小单位：假设有操作集合{A,B,C,D,E} 要么成功, 要么失败

        - 事务T对账号A,账号B进行操作,假设故障发生在A之后,B之前.故障修复后便会出现不一致的状态, 这就需要通过日志进行回滚(恢复系统)

    - Consistent(一致性): 事务必须确保将数据库从一个有效状态更改为另一个有效状态

        - 同一个数据不能有不同的值

        - 当事务开启后每一条修改数据库的语句, 会使数据库不一致, 因此事务提交或回滚时, 必须保持数据库一致性

    - Isolation(隔离性):ACID中最为复杂的。多个事务并发执行时, 需要通过可串行化(并发控制), 实现相互隔离

        - 并发的本质是时序的不确定性，当这些不确定时序的作用域有一定冲突（Race）时就可能会引发各种各样的问题，这一点和多线程编程是类似的

        - 使用 `INSERT`  `UPDATE` 等语句修改同一数据时, 其中一个事务必须等待另一个事务执行完成后执行

    - Durable(持久性): 事务一旦提交, 对数据修改不会丢失

        - 分布式系统中数据被复制到了各个副本上，并受到副本Ack。但实际情况下，也未必就一定能保证100%的持久性。

- Cascading rollback(级联回滚)

    - T10回滚; 由于T11依赖于T10,因此T11也必须回滚; 而T12依赖于T11,因此T12也必须回滚

        ![image](./Pictures/rdbms/rollback.avif)

#### 并发控制(隔离性等级的实现)

##### 隔离性等级

| 隔离性等级                  | 脏读     | 不可重复读 | 幻读 |
|-----------------------------|----------|------------|------|
| 未提交读(read uncommmitted) | 出现     | 出现       | 出现 |
| 已提交读(read committed)    | 不会出现 | 出现       | 出现 |
| 可重复读(repeatable read)   | 不会出现 | 不会出现   | 出现 |
| 可串行化(serializable)      | 不会出现 | 不会出现   | 不会出现 |

| 隔离性等级                  | 内容                                                                                                   |
|-----------------------------|--------------------------------------------------------------------------------------------------------|
| 未提交读(read uncommmitted) | 隔离性最低。                                                                                           |
| 已提交读(read committed)    | 只允许读取已提交的的数据，避免了脏读。会出现不可重复读、幻读                                           |
| 可重复读(repeatable read)   | 当前事务只能读取本事务所做出的修改。但隔离范围不包含插入操作，即事务还是会读到其他事务提交的新增数据。 |
| 可串行化(serializable)      | 事务串行化执行，而不能并发执行。避免脏读、不可重复读、幻读。但实际很好应用，性能低的问题               |
| 快照（snapshot）            | 会出现幻读                                                                                             |

- 大部分数据库默认等级为READ COMMITTED（**已提交读**）；mysql为REPEATABLE READ（**可重复读**）

- 在REPEATABLE READ隔离级别下，尽管解决了不可重复读，但还是存在幻读的问题。

- 解决幻读问题的手段：mvcc或锁
    - 但是大量的锁会严重影响性能。怎样才能不通过加锁还能解决幻读呢？这就是MVCC要做的事情。

- 隔离级别

    - 脏读（未提交读）：用户能不能看到一个还没有提交事务的结果，如果是，就是脏读。

        - 在事务 A 读取数据时，事务 B 读取和修改数据加了共享锁。这种隔离级别，会导致脏读、不可重复读以及幻读。

        - 例子：
            - 手机库存在数据库只剩下1部。
            - 客户A开启查询手机库存的事务，客户B开启购买1部手机的事务（未提交事务）。
            - 此时客户A读到库存为0部
            - 客户B突然不想购买手机，于是回滚事务。手机库存又变为1部

            - 客户A读到的库存0。就是脏读

        - 没有脏读的例子：User1的一个事务分别设置x=3、y=3，但在这个事务提交之前，User2在调用get x时，需要返回2，因为此时User1并没有提交事务。

            ![image](./Pictures/rdbms/没有脏读的例子.avif)

        - 防止脏读的意义：
            - 如果是单对象事务，客户端会看到一个一会即将可能被回滚的值，如果我需要依据这个值做决策，就很有可能会出现决策错误。

            - 如果是多对象事务，可能客户端对于不同系统做访问时一部分数据更新，一部分未更新，那样用户可能会不知所措。

    - 脏写：一个客户端覆盖了另一个客户端尚未提交的写入

        - 例子：对于一个二手车的交易，需要更新两次数据库实现，但有两个用户并发的进行交易，就可能存在销售列表显示交易属于Bob但发票却发给了Alice，因为两个事务对于两个数据的相同记录互相覆盖。

            ![image](./Pictures/rdbms/脏写.avif)

    - 已提交读、读偏差（不可重复读）：同一个事务读到的一条记录的值不一样

        - 在事务 A 读取数据时增加了共享锁，一旦读取，立即释放锁，事务 B 读取修改数据时增加了行级排他锁，直到事务结束才释放锁。也就是说，事务 A 在读取数据时，事务 B 只能读取数据，不能修改。当事务 A 读取到数据后，事务 B 才能修改。这种隔离级别，可以避免脏读，但依然存在不可重复读以及幻读的问题。

        - 例子：
            - 手机库存在数据库只剩下1部。
            - 客户A开启查询手机库存的事务（事务未完成）读到值为1，客户B开启购买1部手机的事务（提交事务）。
            - 此时客户A再次查询，读到库存为0部

                - 客户A在同一个事务读到的一条记录的值不一样，出现不可重复读

        - 例子：Alice在两个银行账户总共有1000块，每个账户500，现在她想从一个账户向另一个账户转账100，并且她想一直盯着自己的两个账户看看钱是否转成功了。不巧的是，他第一次看账户的时候转账还没发生，而成功后只查了一个账户的值，正好少了100，所以最后加起来会觉得自己少了100元。

            - 其实只是个临时性的现象，后面再查询就会得到正确的值，但是如果基于这样的查询去做别的事情，那可能就会出现问题了，比如将这个记录Select出来进行备份，以防DB崩溃。但不巧如果后面真的崩溃，如果基于这次查询到的数据做备份，那这100元可能真的永久的丢失了。如果是这样的场景，不可重复读是不能被接受的。

            ![image](./Pictures/rdbms/读偏差（不可重复读）.avif)

    - 可重复读、写偏差（幻读）：事务的写入需要依赖于之前判断的结果，而这个结果可能会被其他并发事务修改。

        - 在事务 A 读取数据时增加了共享锁，事务结束，才释放锁，事务 B 读取修改数据时增加了行级排他锁，直到事务结束才释放锁。也就是说，事务 A 在没有结束事务时，事务 B 只能读取数据，不能修改。当事务 A 结束事务，事务 B 才能修改。这种隔离级别，可以避免脏读、不可重复读，但依然存在幻读的问题。

        - 幻读与不可重复读有点类似：都是2次读到不一样的值。
            - 幻读：多一条记录
            - 不可重复读：同一条记录

        - 例子：
            - 手机库存在数据库只剩下1部。
            - 客户A开启购买1部手机的事务（事务未完成）读到值为1，客户B开启增加1部手机库存的事务（提交事务）。
            - 此时客户A再次查询，读到库存为1部，本来应该是0

        - 例子：有两个人Alice和Bob决定是否可以休班，做这个决定的前提是判断当前是否有两个以上的医生正在值班，如果是则自己可以安全的休班，然后修改值班医生信息。但由于使用了快照隔离（后面会介绍）机制，两个事务返回的结果全都是2，进入了修改阶段，但最终的结果其实是违背了两名医生值班的前提。

            ![image](./Pictures/rdbms/写偏差（幻读）.avif)

            - 也就是说两个并发的事务，其中一个事务更改了另一个事物的查询结果，这种查询一般都是查询一个聚合结果，例如上文中的count或者max、min等，这种问题会在下面场景中出现问题。
                - 抢订会议室
                - 多人游戏更新位置
                - 唯一用户名

    - 可序列化（Serializable）：

        - 在事务 A 读取数据时增加了共享锁，事务结束，才释放锁，事务 B 读取修改数据时增加了表级排他锁，直到事务结束才释放锁。可序列化解决了脏读、不可重复读、幻读等问题，但隔离级别越来越高的同时，并发性会越来越低。

    - 各种隔离级别所能解决的问题
        ![image](./Pictures/rdbms/各种隔离级别所能解决的问题.avif)

##### mvcc

- 快照（snapshot)：指的是系统一瞬间的一致性状态，保证事务之间彼此隔离。

- 在mvcc机制中：数据会在内存中同时保存多个版本。这为事务的快照读提供了基础

    - 事务对数据修改，会在mvcc链表头上追加一个元素
        - 写事务的编号（transaction_id）
        - 时间戳
        - 修改的数据

    - 事务的读取：会从mvcc链表的头部开始查找，根据当前事务的快照和在元素中修改的事务编号（transaction_id）来判断是否可读；如果不可读则向链表尾部方向移动，直到找到事务可读的版本

- MVVC 对普通的 Select 不加锁，如果读取的数据正在执行 Delete 或 Update 操作，这时读取操作不会等待排它锁的释放，而是直接利用 MVVC 读取该行的数据快照（数据快照是指在该行的之前版本的数据，而数据快照的版本是基于 undo 实现的，undo 是用来做事务回滚的，记录了回滚的不同版本的行记录）。MVVC 避免了对数据重复加锁的过程，大大提高了读操作的性能。

##### 锁

- 共享锁(shared-mode lock):
    - 可读但不能写

- 排他锁(exclusive-mode lock):

    - 可读可写

- 相容锁与不相容锁:

    - 事务A给数据项Q加A锁后, 事务B也能给数据Q加B锁.那么A锁和B锁是**相容的**,反之则不相容

    - 不相容的锁需要等待锁的释放

    - 共享锁与共享锁相容, 与排他锁不相容

- 并发控制器:

    - 事务需要对数据项Q申请锁时, 事务会将请求发送给并发控制器, 事务只有在并发控制器授予锁后才能进行下一步操作.

    - 如果Q已经有一个A锁, 而事务申请的B锁与A锁不相容, 则并发控制器要等待A锁释放后才会授予B锁

- 死锁(deadlock):

    - 当死锁发生后必须回滚两个事务中的一个

        ![image](./Pictures/rdbms/deadlock.avif)

        - 1.T3有B的排他锁

        - 2.T4有A的共享锁, 并打算申请B的共享锁,从而等待T3释放B锁

        - 3.T3打算申请A的排他锁, 从而等待T4释放A锁

        - 4.T3等待T4, T4等待T3.两个事务互相等待对方,导致死锁

    - 死锁预防:

        - 锁超时(lock timeout):

            - 事务申请的锁等待一定时间之后, 就回滚

            - 然而很难判断应该定多长时间

        - 抢占(preempted)

            - 通过timestamp(时间戳)控制抢占

            - 假设timestamp的分配为T1:5, T2:10, T3:15. 并且事务T2, T3申请的锁, 被T1锁持有
                - wait-die(非抢占机制):T2等待, T3回滚

                - wound-wait(抢占机制):T1回滚, T2授予, T3等待

    - 死锁检测:

        ![image](./Pictures/rdbms/deadlock_detection.avif)

        - 使用等待图(wait-for graph)结构, 有环则存在死锁

        - 为了解除死锁, 需要选择一个事务进行回滚, 应遵循最小代价, 然而最小代价很难衡量

            - 彻底回滚:中止事务

            - 部分回滚:需要维护正在运行事务的额外信息, 即锁的申请,授予记录

- 饿死(starved):

    - 流程:

        - 1.事务T1在数据项Q持有共享锁, 而T2对Q申请排他锁,等待T1的释放

        - 2.同时T3, T4对Q申请共享锁,由于锁是相容的因此直接授予

        - 3.导致T2总是得不到排他锁的授予.也就是饿死

    - 解决办法:

        - 增加并发控制器授予锁的条件:一个事务的申请, 不能被其后事务的申请阻塞. 即T3不能先于T2

###### 严格两阶段封锁协议(strict two-pyhase locking protocol):

- 1.增长阶段(growing phase): 事务可以获得锁, 但不能释放锁

- 2.缩减阶段(shrink phase):  事务可以释放锁, 但不能获得新锁

- 最初,事务处于增长阶段, 获得锁; 一旦事务释放锁, 就进入缩减阶段,不能再申请锁

- 不能保证死锁

- 排他锁必须在提交后释放, 防止其他事务的读取. 从而避免级联回滚, 这也是严格两阶段封锁协议里的严格

- 锁转换:

    - 升级:共享锁转换为排他锁

    - 降级:排他锁转换为共享锁

- 锁管理器(lock manager):

    ![image](./Pictures/rdbms/protocol_two-pyhase.avif)

    - 对当前已加锁的数据项维护的一个链表

    - 5个数据项I4, I7, I23, I44, I912.采用溢出链, 即锁表的每个数据项都维护一个链表

        - 事务T23持有I912, I7的锁, 并等待I4

    - 使用数据项名称为索引的散列结构来查找链表中的数据项

    - 这个算法保证了无饿死

    - 算法流程:

        - 锁管理器收到加锁请求时: 如果对应的数据项Q的链表存在, 则在末尾添加一个记录; 否则,就新建Q的链表

        - 锁管理器收到解锁请求时: 删除对应的数据项Q链表记录, 然后检查并处理Q后面的记录

###### 图的协议

![image](./Pictures/rdbms/protocol_tree.avif)

- 只能使用排他锁

- 由于采用树形结构, 每个数据项最多加一次锁, 加锁需要持有数据项的父锁

- 优点:

    - 不会产生死锁

- 缺点:

    - 对数据项J加锁, 就需要对A, B, D, H数据项加锁.导致额外的开销, 并发度降低

###### 多粒度机制(granularity)

- 多粒度机制:

    - 当事务需要访问整个数据库, 如果需要对每个数据项都加锁, 则很费时.应该是直接对整个数据库加锁

    - 当事务需要少量数据项, 则对其数据项加锁

- 树结构: database -> area -> file -> record
    ![image](./Pictures/rdbms/protocol_granularity.avif)

- 加锁是自上而下的, 释放是自下而上的

- 当事务对Fa文件加锁时, 则会对Fa**显式**(explicit lock)加锁, 以及对其后面的结点即ra1, ra2...记录进行**隐式**(implicit lock)加锁

- 在事务对Fa结点显式加锁, 需要对该结点的所有父结点, 加上**意向锁**.这样其他事务就不必搜索整棵树, 就能判断结点有无加锁

- 意向锁的相容性

    ![image](./Pictures/rdbms/intention_lock.avif)

    - 共享意向锁(inention-shared(IS) mode):子结点只能加共享锁

    - 排他意向锁(inention-exclusive(IX) mode):子结点只能加共享锁或排他锁

    - 共享排他意向锁(shared and inention-exclusive(SIX) mode):子结点只能加排他锁

- T1, T3, T4事务为读取操作, 因此可以并发执行. T1, T2 可以并发执行, 但不能与T3并发执行

    - T1读文件Fa记录ra2, 那么需要对数据库, 区域A, Fa加IS锁. 最后给ra2加S锁

    - T2修改文件Fa记录ra9, 那么需要对数据库, 区域A, Fa加IX锁. 最后给ra9加X锁

    - T3读文件Fa所有记录, 那么需要对数据库, 区域A加IS锁. 最后给Fa加S锁

    - T4读整个数据库, 那么直接对数据库加S锁

##### 时间戳排序协议(timestamp-orderind protocol)

- timestamp(时间戳)

    - 系统时间作为timestamp

    - 逻辑计数器作为timestamp

- 为每个数据项分配一个timestamp, 维护读写两个timestamp

    - W-timestamp(Q):成功执行wirte(Q)的事务

    - R-timestamp(Q):成功执行read(Q)的事务

- 事务T发起read(Q):

    - TS(T) < W-timestamp(Q):拒绝read, 回滚T

    - TS(T) >= W-timestamp(Q):执行read

- 事务T发起write(Q):

    - TS(T) < R-timestamp(Q):拒绝write, 回滚T

    - TS(T) < W-timestamp(Q):拒绝write, 回滚T

    - 其他情况:执行write

- Thomas写规则:

    ![image](./Pictures/rdbms/thomas.avif)

    - 流程:

        - T27的read(Q)执行成功

        - T28的write(Q)执行成功

        - T27的write(Q), 由于TS(T27) < W-timestamp, 因此拒绝write, T27回滚

        - 最终导致T27的read(Q)也回滚了

    - 添加Thomas规则,让T27只拒绝write:

        - TS(T) < W-timestamp(Q):表示T已经过时了, 因此拒绝write, 但不回滚T

- 优点:

    - 不产生死锁

- 缺点:

    - 存在长事务饿死

    - 该协议是悲观的, 因为检测到冲突就会等待或回滚

##### 有效性检测协议(validation protocol)

- 该协议适合大部分事务是只读的情况

- 3个timesatmp:

    - start(T):事务T的开始时间

    - validation(T):事务T完成读阶段的时间

    - finish(T):事务T完成写阶段的时间

- 事务T根据是只读还是更新, 按2或3个阶段执行:

    - 读阶段: 数据项保存在事务T的局部变量中, write操作在局部变量进行

    - 有效性检测阶段: 以下两个条件必须满足其一. 如不满足, 则中止事务

        - finish(T2) < start(T1): T1在T2之前完成, 可串行性得到保证

        - start(T1) < finish(T2) < Validation(T1): T2的写阶段在T1的有效性检测阶段之前完成

    - 写阶段: 将事务T的写操作局部变量写入到数据库

- 优点:

    - 不存在级联回滚

- 缺点:

    - 存在长事务饿死

##### 多版本时间戳排序协议(multivesion timestamp-ordering scheme)

- 时间戳排序协议的扩展

    - Content:Qk版本的值

    - W-timestamp(Q):创建Q版本的事务

    - R-timestamp(Q):成功执行read(Q)的事务

- 事务T发起read(Q):

    - TS(T) < R-timestamp(Q): 读取Q版本的值

    - TS(T) > R-timestamp(Q): R-timestamp(Q)就会更新

- 事务T发起write(Q):

    - TS(T) < R-timestamp(Q):回滚

    - TS(T) > R-timestamp(Q):创建Q的新版本, 将W-timestamp(Q),R-timestamp(Q)初始化为TS(T)

    - TS(T) = W-timestamp(Q):写入Q

- 优点:

    - 读请求从不等待和失败

- 缺点

    - 事务冲突只能回滚, 而不是等待

##### 多版本两阶段封锁协议(multivesion two-phase locking protocol)

- 每个数据项都有一个逻辑计数器的timestamp

- 只读事务:遵循多版本时间戳排序协议

    - 读取ts-counter的值作为该事务的版本

    - 事务T发起read(Q):

        - 只读取Q版本的值

- 更新事务:

    - 更新事务T发起read(Q):

        - 对Q加上共享锁, 然后读取Q的最新版本值

    - 更新事务T发起write(Q):

        - 对Q加上排他锁, 并创建新的版本

- 优点:

    - 只读事务不必等待加锁

##### 快照隔离(Snapshot Isolation)

- 两种方法:

    - 在多版本两阶段封锁协议的基础上:

        - 对只读事务快照, 读取在快照上执行

        - 更新(读写)事务不变

        - 缺点:

            - 系统难以分辨事务是否为只读

    - 对所有事务都进行快照

        - 读取在快照上执行

        - 写入冲突时, 先提交事务赢, 后提交的事务进行回滚

- 优点:

    - 只读事务不必等待加锁

- 缺点:

    - 斜写(skew write):非可串行化

        ![image](./Pictures/rdbms/skew_write.avif)

        - 通过主键可以避免, 数据库会在快照之外检查主键冲突, 回滚其中一方

##### 谓词读(幻读 phantom)

- T1执行:
    ```sql
    select count(*) from instructor
    where dept_name = 'physics'
    ```

- T2执行:
    ```sql
    insert into instructor values
    ('11111', 'James', 'physics', 100000)
    ```
    - 或者
    ```sql
    update instructor
    set dept_name = 'physics'
    where name = 'Wu'
    ```

- T1和T2虽然没有访问共同元组, 但相互冲突

- 解决方法:

    - 1.

        - 禁止其他事务创建和更新`dept_name = 'physics'`的元组

        - 索引封锁:以B+树为例, 修改或读取必然需要访问对应的physics叶结点, 因此封锁叶节点可以避免谓词冲突

    - 2.谓词锁:对`dept_name = 'physics'`加上**谓词锁**. 如果插入,更新,删除操作满足谓词,则需要等待

        - 相比与方法1,代价很大,因此在实践中不常见

##### 索引并发

- 索引非串行并发:事务在两次索引查询期间,索引结构发生变化, 只要能返回正确的元组, 是可接受的

- 两者方法:

    - 蟹行协议(crabbing protocol):

        - 在根结点加上共享锁, 再对子结点获取共享锁, 释放父结点的锁, 反反复复直至叶结点. 如果是插入和删除就需要对叶结点加上排他锁

            - 如果B+树出现合并或分裂有可能会出现死锁, 则需要从树根重新搜索

    - B-link树:

        - 如果出现合并或分裂, 导致指针错误, 则会向该结点的右兄弟结点查找

## 日志(恢复系统)

- 更新日志记录(update log record):
    ![image](./Pictures/rdbms/log_record.avif)

    | 日志记录             | 内容                               |
    |----------------------|------------------------------------|
    | `<T0, A, 1000, 950>` | 表示数据项A的旧值是1000, 新值是950 |
    | `<T start>`          | 事务T开始                          |
    | `<T commit>`         | 事务T提交                          |
    | `<T abort>`          | 事务T中止                          |


- 系统故障后:

    - redo(T):重做事务T

        - 日志包含:`<T start>`, `<T commit>`或`<T abort>`记录时, 就会对事务T进行重做.注意:`<T abort>`也需要重做

        - 重做:将事务T更新过所有数据项的值设置成**新值**

    - undo(T):撤销事务T

        - 日志包含:`<T start>` 就会对事务T进行撤销

        - 撤销:将事务T更新过所有数据项的值设置成**旧值**

        - redo-only日志:将撤销的操作记录到特殊redo-only日志
            - 记录格式:`<T 数据项 旧值>`

    - `<checkpoint L>`:检测点记录

        - 系统崩溃后需要搜索整个日志, 因此在日志加入`<checkpoint L>`记录, 表示`<checkpoint L>`之前的记录已经写入数据库了.redo, undo只需执行之后的记录

<span id="undo-list"></span>
- undo-list(撤销列表)流程:

    - 1.从最后一个`<checkpoint L>` 记录后扫描日志

        - 2.发现`<Ti start>`记录时, 就把Ti添加到undo-list

        - 3.发现`<Ti commit>`或`<Ti abort>`记录时, 就把Ti从undo-list去掉

    - 4.扫描完后.开始撤销阶段,从尾部开始反向扫描日志进行回滚

        - 5.发现`<Tj start>`记录时, 就往日志写入`<Tj abort>`记录, 并把Tj从undo-list去掉

        - 6.一旦undo-list变为空表, 则撤销阶段结束

    - 假设系统崩溃在`<T0 abort>`

        ![image](./Pictures/rdbms/log_check.avif)

        - 1.undo-list初始发现T0, T1时, 就添加到表里

        - 2.当发现`<T1 commit>`, 把T1从表里去除

        - 3.当发现`<T2 start>`, 就添加到表里

        - 4.当发现`<T0 abort>`, 把T0从表里去除

        - 5.扫描结束, 此时表里只剩下T2. 开始撤销阶段, 从尾部开始反向

        - 6.把T2恢复为旧值也就是`<T2 A 500>`记录

        - 7.当发现`<T2 start>`, 就把`<T2 about>`记录添加到日志, 并把T2从列表去掉

        - 8.undo-list为空,撤销阶段结束

- 日志缓冲区:

    - 一条日志记录比磁盘块要小得多, 则日志在磁盘上会大的多.因此最好一次写入多条记录,在此之前写入日志缓冲区

    - WAL(先写日志):为了保证原子性, 事务T提交写入磁盘之前, 必须先将日志写入磁盘

    - 闩锁(latch):事务T写入磁盘前, 需要获取数据项对应的块的排他锁

        - 这个锁与并发控制的锁无关, 不需要两阶段的可串行化

- 模糊检查点(fuzzy checkpointing):

    - 如果`<checkpoint L>`的时间很长, 那么事务就会中断很久

    - 模糊检查点:`<checkpoint L>`记录写入日志后, 缓冲区才开始写入硬盘.写入完成后,加上`<last_checkpoint>`记录

### 逻辑日志

- 逻辑操作:操作时获取低级别锁,完成后释放. 插入和删除是这一类例子

- 逻辑日志只用于撤销,不用于重做:

    - `<T, O, operation-begin>`: 逻辑undo在修改索引的操作之前添加的日志记录

    - `<T, O, operation-end>`: 操作结束

    - `<T, O, operation-abort>`: 逻辑回滚扫描不到`<T, O, operation-end>`时, 就会减少或添加对应的值, 而不是恢复旧值, 然后添加`<T, O, operation-abort>`记录

- 逻辑回滚:

    - 例子1:

        ![image](./Pictures/rdbms/log_logical-undo.avif)

        - 1.数据项C通过添加一个值进行回滚, 对应`<T0, C, 400, 500>`记录

        - 2.数据项B是物理回滚, 对应`<T0, B, 2000>`记录

        - 3.而T1对数据项C的更新得以保留

    - 例子2:

        - 系统崩溃在`<T2, C, 400, 300>`:

        ![image](./Pictures/rdbms/log_logical-undo1.avif)

        - 1.undo-list包含T1,T2

        - 2.撤销阶段, 使用物理日志对T2的05进行撤销, 对应`<T2, C, 400>`记录,并记录到redo-only日志

        - 3.当发现`<T2 start>`, 就把`<T2 about>`记录添加到日志, 并把T2从undo-list列表去掉

        - 4.当发现`<T1, O4, operation-end, (C + 300)>`, 通过添加一个值进行逻辑undo, 对应`<T1, C, 400, 700>`记录, 然后添加`<T1, 04, operation-abort>`记录

        - 5.当发现`<T1, O4, operation-begin>`, 使用物理日志对T2的05进行撤销, 对应`<T1, B, 2050>`记录,并记录redo-only日志.并把T1从undo-list列表去掉

### ARIES: 目前最新的恢复技术

- 使用LSN(日志顺序号)标识日志记录

    - 恢复独立性:页能独立恢复

- 支持物理逻辑操作:有逻辑, 物理页

- 多日志:当一个日志达到限度, 就会拆分, 每个文件有个文件号

- ARIES数据结构:

    ![image](./Pictures/rdbms/aries_structures.avif)

    - 脏页表(dirtypage table):

        - PageLSN(页日志顺序号): 每一个更新操作, 将更新页的LSN记录到PageLSN

        - RecLSN:记录未写入磁盘的LSN

- ARIES恢复流程:

    - PrevLSN:当前日志记录中, 指向同一事务的前一条日志记录的LSN

    - checkpoint log record(检测点日志记录):包含脏页表

    - CLR(补偿日志记录):类似redo-only日志, 回滚产生的日志记录

        - UndoNextLSN:指向下一个undo的日志LSN

    - 恢复流程中的3个阶段:

        - 分析阶段:

            - 1.找到最后的`<checkpoint log record>`读取其脏页表, 将RedoLSN设置为RecLSN中的最小值

            - 2.然后正向扫描类似[undo-list](#undo-list)

        - 重做阶段:

            - 从RedoLSN开始正向扫描, 如果不在脏页表或LSN小于RecLSN, 就跳过

        - 撤销阶段:

            - 对undo-list列表进行撤销, 并设置CLR的UndoNextLSN为PrevLSN

    - 系统崩溃在LSN 7571:

        ![image](./Pictures/rdbms/aries_structures.avif)

        - 1.分析阶段从`<checkpoint log record>`的LSN开始, 也就是LSN 7568

        - 2.分析阶段完成后:RedoLSN为7564, undo-list列表包含事务T145

        - 3.重做阶段从7564开始, 由于小于`<checkpoint log record>`的7568, 因此不会将修改过的页面写入磁盘

        - 4.撤销阶段需要回滚T145, 因此从7567开始反向扫描至7563

## JOIN(关联查询): 改变表关系

- [数据库表连接的简单解释](http://www.ruanyifeng.com/blog/2019/01/table-join.html?utm_source=tuicool&utm_medium=referral)

- [图解 SQL 里的各种 JOIN](https://zhuanlan.zhihu.com/p/29234064)

- [MySQL 的 join 功能弱爆了？](https://zhuanlan.zhihu.com/p/286581170)

### 基本概念

从两个或更多的表中获取结果.[图解 SQL 里的各种 JOIN](https://zhuanlan.zhihu.com/p/29234064)

- 只返回两张表匹配的记录,这叫内连接(inner join)
- 返回匹配的记录,以及表 A 多余的记录,这叫左连接(left join)
- 返回匹配的记录,以及表 B 多余的记录,这叫右连接(right join)
- 返回匹配的记录,以及表 A 和表 B 各自的多余记录,这叫全连接(full join)

![image](./Pictures/rdbms/join.avif)

![image](./Pictures/rdbms/join1.avif)

### join的实现

Nested-Loop Join(嵌套循环连接)

- Nested-Loop Join 区分驱动表和被驱动表,先访问驱动表,筛选出结果集,然后将这个结果集作为循环的基础,访问被驱动表过滤出需要的数据

- 被驱动表(内层表)只需一次磁盘搜索

#### SNLJ(简单嵌套循环):

- 驱动表的结果集作为循环基础数据: 从结果集取出一条条数据(图中的R1, R2...)与被驱动表(图中的S1, S2)一一匹配(Sn次), 然后合并数据

- 对于表r的每一条记录, 需要对表s作完整的搜索. 代价很大

![image](./Pictures/rdbms/join_SNLJ.avif)


#### 代价分析

- 假设合并student和takes两个表

    | 行数和磁盘数    | 数量  |
    |-----------------|-------|
    | student行数     | 5000  |
    | student磁盘块数 | 100   |
    | takes行数       | 10000 |
    | takes磁盘块数   | 400   |

    - Nr: r表的行数
    - Ns: s表的行数
    - Br: r表的磁盘块数
    - Bs: s表的磁盘块数

- 最好的情况: 内存能容纳两个表

    - (Br + Bs)块的传输次数 + 两次磁盘搜索

    - `students磁盘块 + takes磁盘块 + 两次磁盘搜索` = `100 + 400 + 两次磁盘搜索`

- 最坏的情况: 内存只能容纳一个数据块

    - (Nr * Bs + Br)块的传输次数 + (Nr + Br)磁盘搜索次数

    - 假设student是外层循环, takes是内层循环:

        - `students行数 * takes磁盘块 + students行数 + students磁盘块` = `5000 * 400 + 5000 + 100`

    - 假设takes是外层循环, student是内层循环:

        - `10000 * 100 + 10000 + 400`

    - 两者对比: 假设块传输0.1毫秒, 磁盘搜索4毫秒

        - student为外层:2000100块传输 + 5100磁盘搜索

            - 200010 + 20400 = 220410

        - takes为外层:1000400块传输 + 10400磁盘搜索

            - 块的传输少了, 但磁盘搜索多了

            - 100040 + 41600 = 141640

        - takes虽然记录和块更多, 但作为外层更优

#### block nested-loop(块嵌套循环):

- MySQL

    - 加入了join buffer: 缓存 join 需要的字段, 降低了循环的次数,也就是被驱动表的扫描次数

    - MySQL 默认 buffer 大小 256K,如果有 n 个 join 操作,会生成 n-1 个 join buffer

![image](./Pictures/rdbms/join_BNLJ.avif)

#### 代价分析

- 内层表的每一块与外层表的每一块形成一对

    - 块中的行与另一个块中的行形成行对

- 最好的情况: 和简单循环一样 `100 + 400 + 两次磁盘搜索`

- 最坏的情况: 内外层表的每一块都只需读取一次

    - (Br * Bs + Br)块传输 + (2br)磁盘搜索

    - 100 * 400 + 100 + 2 * 100

    - 40100次块传输 + 200次磁盘搜索

    - 对比简单嵌套: 假设块传输0.1毫秒, 磁盘搜索4毫秒

        - 4010 + 800 = 4810毫秒

        - 比简单嵌套优

#### INLJ(索引嵌套循环):

- 一般行数少的作驱动表(外层表)

![image](./Pictures/rdbms/join_INLJ.avif)

#### 代价分析

- 最坏的情况: 内存只能容纳一个数据块

    - 假设student是外层循环, takes是内层循环:

       - (Hs + 1): 假设每个结点为20个索引, takes有10000行, 那么高度为4, 存储数据还需要一次磁盘访问, 因此是(4 + 1)

       - Br + Nr * (Hs + 1) = 100 + 5000 * 5

       - 25100次磁盘搜索和块传输

    - 对比简单嵌套和块嵌套: 假设块传输0.1毫秒, 磁盘搜索4毫秒

        - 2510 + 100400 = 102910

        - 比简单嵌套优, 但比块嵌套差

            - 除非student表上的某一列行数显著减少, 那么可以比块嵌套更优

#### merge join(归并连接)

- 先排序, 再为每个表分配一个指向第一行的指针, 指针会遍历整个表

![image](./Pictures/rdbms/join_merge.avif)

#### 代价分析

- 最好的情况已排序, 并且分配Bb(缓存块). 1Bb大小为1.6M = 400块:

    - (Br + Bs)块传输 + ([Br / Bb] + [Bs / Bb])磁盘搜索

    - 100 + 400 + 2

- 最坏的情况没有排序, 内存只能容纳3块

    - takes表:

        - 400 * (2 * [log3-1 (400 / 3)] + 1) = 6800次块传输

        - 400 * (2 * (400 / 3) + 400 * (2 * 8 -1)) + 400 = 6668次磁盘搜索

    - students表:

        - 100 * (2 * [log3-1 (100 / 3)] + 1) = 1300次块传输

        - 100 * (2 * (100 / 3) + 100 * (2 * 8 -1)) + 100 = 1264次磁盘搜索

    - 一共9100次块传输, 8932次磁盘搜索

- 假设分配1个Bb(缓存块)

    - 一共1640次磁盘搜索

- 假设分配5个Bb(缓存块)

    - 一共2500次块传输, 251次磁盘搜索

- 混合归并:
    - 假设1个表已排序, 另一个表没有排序, 但连接列有B+树的辅助索引

    - 可以把已排序的表与使用B+树辅助索引进行归并

#### hash join(散列连接)

- 表r与表s的连接条件必然会有**相同的值**

    - 假设相同的值为i, 则比较ri, si的散列值

![image](./Pictures/rdbms/join_hash.avif)

## HTAP(Hybrid transaction/analytical processing) 混合事务 / 分析处理

- [What is HTAP?](https://en.pingcap.com/blog/how-we-build-an-htap-database-that-simplifies-your-data-platform)

- OLTP(Online Transactional Processing) 在线事务处理

    - 强调快速查询, 更可能是**行数据库**, 每次修改不超过几行, 以事务/s衡量效率
    - 一般用于交易服务, 如mysql

- OLAP(Online Analytical Processing) 在线分析处理

    - 强调响应时间, 更可能是**列数据库**, 事务较少, 查询复杂通常涉及aggregating(聚合)历史数据

    - 一般用于数据挖掘, 如hadoop

- OLTP数据库保存数据, 并定期提取数据; 再使用OLAP数据库进行分析, 导出报告或者写回OLTP数据库

    - 这一过程复杂漫长, 延迟高

- 而HTAP数据库便是兼容两者, 不需要在一个数据库里执行事务, 另一个数据库里分析

    ![image](./Pictures/database_concept/htap.avif)

### 列存储

![image](./Pictures/rdbms/column.avif)

- 优点:

    - 读取性能更高:

        - 例子:查询过去1年的price(价格)

            - 行存储需要读取过去1年的所有行, 然后聚合price字段

            - 列存储只需读取price字段

    - 压缩性能更高:

        - 相识的数据存储在一起, 压缩性能更高

- 缺点:

    - 更新性能低

        - 更新一行, 需要更新每一列

## 第三方工具

- [在线创建数据库的实体-关系图的工具 dbdiagram](https://dbdiagram.io)

- [natural-sql：文本生成sql的llm模型](https://github.com/cfahlgren1/natural-sql)

- [SQLkiller：在线的AI生成sql语句](https://www.sqlkiller.com/)

- [sql-formatter：sql语句格式化的js库](https://github.com/sql-formatter-org/sql-formatter)

- [Migrate：数据库迁移/变更工具](https://github.com/golang-migrate/migrate)

    - 支持 MySQL、MariaDB、PostgreSQL、SQLite、Neo4j、ClickHouse 等不同类型的数据库。

- [sqlmap: 自动检测和利用 SQL 注入漏洞，获得数据库服务器的权限。](https://github.com/sqlmapproject/sqlmap)

- [SQLGlot：sql转换器，支持20多种如DuckDB, Presto / Trino, Spark / Databricks, Snowflake, and BigQuery.](https://github.com/tobymao/sqlglot)
    ```py
    import sqlglot

    # SQL 转 Spark
    sql = """WITH baz AS (SELECT a, c FROM foo WHERE a = 1) SELECT f.a, b.b, baz.c, CAST("b"."a" AS REAL) d FROM foo f JOIN bar b ON f.a = b.a LEFT JOIN baz ON f.a = baz.a"""
    print(transpile(sql, write="spark", identify=True, pretty=True)[0])
    ```

- 客户端

    - [dbgate：MySQL, PostgreSQL, SQL Server, MongoDB, SQLite and others的gui](https://github.com/dbgate/dbgate)

    - [harlequin：sql tui](https://github.com/tconbeer/harlequin)
        ```sh
        // sqlite
        harlequin -a sqlite "path/to/sqlite.db" "another_sqlite.db"

        // DuckDB
        harlequin "path/to/duck.db" "another_duck.db"

        // mysql
        pip install harlequin-mysql
        harlequin -a mysql -h localhost -p 3306 -U root --password example --database dev
        ```

    - [Chat with your SQL database 📊. Accurate Text-to-SQL Generation via LLMs using RAG](https://github.com/vanna-ai/vanna)
